{
  
  "0": {
    "title": "Acknowledgements",
    "content": "Acknowledgements . ScreenBEAM2 was original developed by Jiyang Yu, with substantial design input from Xinge Wang. We are grateful to Chenxi Qian for package wrapping up and maintainance. . Funding Supports . This work was supported by NIH grant. The work was also supported by St. Jude grants. .",
    "url": "http://localhost:4000/docs/Acknowledgements.html",
    "relUrl": "/docs/Acknowledgements.html"
  }
  ,"1": {
    "title": "Installation",
    "content": "Installation . Install blat . You can install blat from conda: . conda install -c bioconda blat which blat . If you are running ScreenBEAM on local node, please make sure your blat has been linked to your local bin. . Install ScreenBEAM2 package . Install R package from source . In your R session, please run . install.packages(path_to_file, type=&quot;source&quot;,repo=NULL) . or . devtools::install_local(path_to_file) . R package from github . devtools::install(pkg=&#39;.&#39;, dependencies = T) devtools::install_deps(pkg = &quot;.&quot;, dependencies = TRUE) ## Install package dependencies if needed. .",
    "url": "http://localhost:4000/docs/Installation.html",
    "relUrl": "/docs/Installation.html"
  }
  ,"2": {
    "title": "Tutorial - Mapping",
    "content": "Tutorial - Mapping via ScreenBEAM2 . ScreenBEAM2 is a R based tool which consists of three major parts for processing steps: 1. mapping long read sequence to short read libraries, 2. Quality control, data cleanning and data preprocessing for mapped raw counts data; 3. Differential representative analysis on gene level or shRNA level. . This is the first part of the whole tutorial, which is focused on mapping your long read fastq file with short read libraries. . . Step1.Mapping to library Step1.1 Prepare raw fastq and library files | Step1.2 Mapping and collecting raw counts | Step1.3 Mapping qualtiy control | Step1.4 Read your mapping quality control | | Step1.Mapping to library . Step1.1 Prepare raw fastq and library files . First of all, define your project name and create a project R object. This could be achieved by function ScreenBEAM.dir.create. . note: Project object should be library based! One library per run of ScreenBEAM2! If you have multiple libraries mapped at the same time, you have to open different R project for different library runs. Our only allows one library at a time. . lib.name&lt;-&#39;[your_library_name_+_project_name]&#39; analysis.par&lt;-ScreenBEAM.dir.create(project_main_dir = &#39;./&#39;, lib_name = lib.name, DATE = T) analysis.par$par.path&lt;-analysis.par$out.dir analysis.par$par.name&lt;-paste0(&quot;analysis_par_&quot;,lib.name, &quot;.RData&quot;) save.image(file = paste0(analysis.par$par.path, analysis.par$par.name)) #save your image . Next, soft link your fastq file to analysis.par$out.dir.fastq folder. This step is ESSENTIAL, please DON’T move files directly, in case of losing your data. Before you soft link data files, we suggested double check your fastq files with your meta data, to make sure all fastq files were mapped to your designated library. . You can go to your analysis.par$out.dir.fastq folder, then run command: . ln -s file1 ln -s file2 ... . or if you would like to link all fastq files in one folder, you can simply run: . ln -s [your folder path]/*_R1_001.fastq . . Then put your library csv file in the analysis.par$out.dir.library folder. The 1st column must be gRNA name and 2nd column must be sequence. An example library file would be like: . id seq gene . TargetMouse.sg1 | AAAAAGAAATGCTCTACCAG | Ypf1 | . TargetMouse.sg2 | AAAACACATACGTCTGTGAG | Cwc12 | . TargetMouse.sg3 | AAAACCGAGCACCATCAATG | Lck2 | . Then go to analysis.par$out.dir.library folder and run following command to create fasta file for library. . awk FNR-1 your_library.csv | awk -F &quot;,&quot; &#39;{print &quot;&gt;&quot;$1&quot; n&quot;$2}&#39; &gt; your_library.fa&quot; . Then you could move forward to mapping and collecting raw counts step, which could be executed either on a high performance computing platform or your local machine. . Step1.2 Mapping and collecting raw counts . First of all, please ensure blat was installed in your working environment, since we will be utilizing blat for library sequence mapping. (You can use blat version here on conda) . NOTE: Please make sure your R is able to recognize blat. Please check whether blat has been added to your local bin . Next, we wil need to execute ScreenBEAM.raw.count function in ScreenBEAM2 R package. This function will help mapping your fastq files to library and collect raw counts by calling BLAT from R. This function will execute 1)get basic statististics, 2) create fasta from fastq and run blat, and 3) collect raw counts sequentially, so it may take a while for large sequencing data or whole genome libraries. Please try using more powerful computing platform if this is your case. . analysis.par&lt;-ScreenBEAM.raw.count(analysis.par) # save your analysis results save(analysis.par, file = paste0(par.path, par.name)) . NOTE: Also, some fastq files are ultra big, you may need to chop them into small fastq files in order to execute them successfully. . Step1.3 Mapping qualtiy control . After mapping is done, please proceed your analysis back in interactive environment (such as R studio). We are going to perform quality control, data annotation and data cleaning . For mapping quality control, we designed a customized QC rmarkdown file, if you have ScreenBEAM2 installed, you can run function ‘ScreenBEAM.mapping.QC’ as follows: . ScreenBEAM.mapping.QC(analysis.par) . If you would like to make adjustment on this rmarkdown file, you can edit it and run your final rmarkdown file as follows: . ScreenBEAM.mapping.QC(analysis.par, QC.Rmd.path = [new_path_to_your_rmd]) . This will output a QC report for your library mapping, here is example qc report, including several useful metrics for mapping rate, mismatch rate, count boxplots, etc. . Step1.4 Read your mapping quality control . Mapping quality control includes 6 differernt metrics to help you understand your library and mapping quality. . Library quality . Library removed RNA due to duplicated or substring of other RNAs This table shows all duplicated gRNAs(either perfect match or substring of other gRNA from the same gene). This will help you understand why some genes has less gRNAs than others. | . . Total count of the gRNA number for each gene. This will help understand your library. Usually, a library contains hundreds or thousands of negative control gRNA (dummy gRNA) instead of 6(normally 6 gRNA for one gene). ScreenBEAM will take care of this unbalanced negative controls, and random sampling negative control guides to match other genes. | . . Mapping quality . Mapping rate barplot. This barplot could help visualize how many reads in your samples’ fastq files are successfully mapped(perfect match) to library sequence. This could not only help you visualize the data quality of your fastq files, but also give a hint of whether to allow mismatch in your raw data collection. | . . Boxplot of raw count distribution in each sample. This plot could help your understand if all samples have similar raw count distribution. It could also give you a hint of how to choose your total number to perform normalization. | . . Proportion of number of mismatch in each sample. This plot could help you understand if all samples have similar mapping quality. | . . Suggestion of number of mismatch to choose for your downstream analysis. This plot visualizes the percentages of different number of mismatch in each samples respectively. If there are two suggested number of mismatch, please use the smaller one. | . .",
    "url": "http://localhost:4000/docs/Tutorial1.html",
    "relUrl": "/docs/Tutorial1.html"
  }
  ,"3": {
    "title": "Tutorial - Cleanning",
    "content": "Tutorial-2 Data annotation and data cleanning . ScreenBEAM2 is a R based tool which consists of three major parts for processing steps: 1. mapping long read sequence to short read libraries, 2. Quality control, data cleanning and data preprocessing for mapped raw counts data; 3. Differential representative analysis on gene level or shRNA level. . This is the second part of the whole tutorial, which is focused on expression set cleaning and meta data integration. . . Step2 Data annotation and data cleanning Step2.1 Create Metadata | Step2.2 Combine mapping info to your metadata | Step2.3 Data normalization and create Expressionset | Step2.4 Qualtiy control for wrapped expressionsets | Step2.5 Prepare tsv file for differential representation analysis | | Step2 Data annotation and data cleanning . Step2.1 Create Metadata . First of all, please have your Metadata information collected in an excel file, and saved it to analysis.par$out.dir.metadata. Please note that, ID that could be matched to sampleID on fastq files is required, as well as proper group informations. A sample metadata file is shown as follows: . sampleID group description replicate expName   .   | F171 | 0.25Hi | 0.25ug nacl-high | A | 2nd round screening in cells using library A | .   | F172 | 0.25Lo | 0.25ug nacl-low | A | 2nd round screening in cells using library A | .   | F173 | 0.25Hi | 0.25ug nacl-high | B | 2nd round screening in cells using library A | . meta &lt;-read.xlsx(file.path(analysis.par$out.dir.metadata,&quot;Metadata.xlsx&quot;), sheet = 1) dim(meta) raw&lt;-analysis.par$raw.count.table s.cur&lt;-data.frame(sampleID.full=names(raw)) #chop sample name into sectors s.cur&lt;-mutate(s.cur, sampleID=gsub(&#39;(.*)_(.*)_(.*)_(.*)_R1_001&#39;,&#39; 2&#39;,sampleID.full), HartwellID=as.numeric(gsub(&#39;(.*)_(.*)_(.*)_(.*)_R1_001&#39;,&#39; 1&#39;,sampleID.full)), HiseqSampleID=gsub(&#39;(.*)_(.*)_(.*)_(.*)_R1_001&#39;,&#39; 3&#39;,sampleID.full), HiseqLaneID=gsub(&#39;(.*)_(.*)_(.*)_(.*)_R1_001&#39;,&#39; 4&#39;,sampleID.full) )#this could be adjusted according to names of your fastq files meta&lt;-left_join(s.cur,meta,by=&#39;sampleID&#39;) # merge sample info from fastq with your meta data dim(meta) . Create unique sample name and index for each sample by pasting sampleID and lane ID together. This could be adjusted accordingly. . meta&lt;-mutate(meta,sampleName=paste(sampleID,HiseqLaneID,sep=&#39;_&#39;), index=paste(HiseqSampleID,HiseqLaneID,sep=&#39;_&#39;)) . Check if there are duplicates in your metadata – this step is crucial because duplicates will affect following data manipulation. . filter(meta,duplicated(sampleName)) filter(meta,duplicated(index)) dim(meta) . Step2.2 Combine mapping info to your metadata . After all mapping jobs are completed and mapping statistics are generated and stored in designated location analysis.par$raw.summary. We could calculate mapping rate, and sequencing coverages from mapping statistics and store them in meta data. . mapping&lt;-analysis.par$raw.summary mapping&lt;-mapping[,c(&#39;sample&#39;,&#39;total&#39;,&#39;n.matched&#39;)] names(mapping)[1]&lt;-&#39;sampleID.full&#39; #calculate mapping rate and sequencing coverages mapping&lt;-mutate(mapping,mappingRate=n.matched/total,coverage.seq=round(n.matched/nrow(analysis.par$raw.count.table))) head(mapping) #combine mapping statistics with meta data, save files meta&lt;-left_join(meta,mapping,by=&quot;sampleID.full&quot;) unlink(file.path(analysis.par$out.dir.output.mapping,&#39;mapping.summary.xlsx&#39;)) write.xlsx(meta,file=file.path(analysis.par$out.dir.output.mapping,&#39;mapping.summary.xlsx&#39;),sheet=&#39;mapping&#39;) . Add sample information to count distribution matrix. . count.dist&lt;-as.data.frame(analysis.par$raw.count.dist) count.dist$sample&lt;-meta$sampleName[match(count.dist$sample,meta$sampleID.full)] names(count.dist)[2]&lt;-&#39;sampleName&#39; . Now we are ready to deal with the count data and create expression sets. . Step2.3 Data normalization and create Expressionset . Then, we could perform data normalization and store different normalization method into eset. Total number of normalization is data dependent, usually we use 1e6. . normalize.total&lt;-1e6 m&lt;-list(samples=meta,features=analysis.par$lib, count.dist=count.dist) save(m, file = paste0(par.path, &quot;raw.list.Rdata&quot;)) . Save your expression matrix based on number of mismatch, this optimal mismatch number could be found in previous mapping QC report, as an example here we use 9. This function will also save an expression set with maximum mismatch and 0 mismatch, for your reference. . saveCountEset(m, save.path=analysis.par$out.dir.output.mapping, n.mismatch = 9) # n.mismatch should be adjusted according to mapping qc . Step2.4 Qualtiy control for wrapped expressionsets . Here we have a build-in QC function imported from NetBID2 – draw.eset.QC to facilitate quality control purpose. Each draw.eset.QC function will output a quality control report for following expression set. . load(paste0(analysis.par$out.dir.output.mapping,&quot;count.9mm.raw.eset&quot;)); raw.9mm&lt;-count.Nmm.raw.eset # assign your eset with a more specific name draw.eset.QC(raw.9mm, outdir = analysis.par$out.dir.output.QC, intgroup = &#39;group&#39;, do.logtransform = T, prefix = &#39;raw.9mm_&#39;, choose_plot = c(&quot;heatmap&quot;, &quot;pca&quot;,&quot;density&quot;,&quot;correlation&quot;,&quot;meansd&quot;)) . Here we could also choose to perform more quality control for different numbers of mismatch, as a reference. . load(paste0(analysis.par$out.dir.output.mapping,&quot;count.9mm.normalized.eset.1M.eset&quot;)); norm.9mm&lt;-count.Nmm.normalized.eset draw.eset.QC(norm.9mm, outdir = analysis.par$out.dir.output.QC, intgroup = &#39;group&#39;, do.logtransform = T, prefix = &#39;norm.9mm_&#39;, choose_plot = c(&quot;heatmap&quot;, &quot;pca&quot;,&quot;density&quot;,&quot;correlation&quot;,&quot;meansd&quot;)) load(paste0(analysis.par$out.dir.output.mapping,&quot;count.maxmm.raw.eset&quot;)); raw.maxmm&lt;-count.maxmm.raw.eset draw.eset.QC(raw.maxmm, outdir = analysis.par$out.dir.output.QC, intgroup = &#39;group&#39;, do.logtransform = T, prefix = &#39;raw.maxmm_&#39;, choose_plot = c(&quot;heatmap&quot;, &quot;pca&quot;,&quot;density&quot;,&quot;correlation&quot;,&quot;meansd&quot;)) load(paste0(analysis.par$out.dir.output.mapping,&quot;count.maxmm.normalized.1M.eset&quot;)); norm.maxmm&lt;-count.maxmm.normalized.eset draw.eset.QC(norm.maxmm, outdir = analysis.par$out.dir.output.QC, intgroup = &#39;group&#39;, do.logtransform = T, prefix = &#39;norm.maxmm_&#39;, choose_plot = c(&quot;heatmap&quot;, &quot;pca&quot;,&quot;density&quot;,&quot;correlation&quot;,&quot;meansd&quot;)) . Step2.5 Prepare tsv file for differential representation analysis . Save normalized data and ids (gene/shRNA) in a tsv file for downstream analysis. . first.2.column&lt;-data.frame(RNAid=analysis.par$lib$id, geneid=analysis.par$lib$gene) count.column&lt;-as.data.frame(exprs(norm.9mm)) count.column$RNAid&lt;-rownames(count.column) final.table&lt;-merge(first.2.column, count.column, by=&quot;RNAid&quot;) colnames(final.table)&lt;-c(&quot;rnaID&quot;,&quot;geneID&quot;, paste(meta$group,meta$replicate, sep = &quot;_&quot;)) write.table(final.table, file = paste0(analysis.par$out.dir.output.DR,&quot;YOUR_PROJECT_9mm_normalized.tsv&quot;), quote = F, row.names = F, sep=&#39; t&#39;) . After writing table, you will be able to quit current working environment and run following analysis on cluster. Or if your data size is moderate, you could stay in your r environment and move forward. .",
    "url": "http://localhost:4000/docs/Tutorial2.html",
    "relUrl": "/docs/Tutorial2.html"
  }
  ,"4": {
    "title": "Tutorial - DR",
    "content": "Tutorial-3 Differential representative analysis . ScreenBEAM2 is a R based tool which consists of three major parts for processing steps: 1. mapping long read sequence to short read libraries, 2. Quality control, data cleanning and data preprocessing for mapped raw counts data; 3. Differential representative analysis on gene level or shRNA level. . This is the third part of the whole tutorial, which is focused on differential representative analysis on gene and shRNA. . . Step3.Perform pairwise comparisons on Gene level | Step4.Perform pairwise comparisons on shRNA level | Step3.Perform pairwise comparisons on Gene level . First, define your comparison pairs and make sure all group names are correct. Here as sample analysis, we used a . unique.group&lt;-unique(m$samples$group) compare.pairs&lt;-combn(unique.group,2) compare.pairs . Here we use function ScreenBEAM.gene.level in ScreenBEAM2 to perform gene level . # Define your input file input.file&lt;-paste0(analysis.par$out.dir.output.DR,&quot;YOUR_PROJECT_9mm_normalized.tsv&quot;) de.gene.list&lt;-list() for(i in 1:dim(compare.pairs)[2]){ case.groupname&lt;-compare.pairs[1,i] control.groupname&lt;-compare.pairs[2,i] case.sample.id&lt;-which(m$samples$group==compare.pairs[1,i]) control.sample.id&lt;-which(m$samples$group==compare.pairs[2,i]) case.postfix&lt;-LETTERS[seq(from=1, to=length(case.sample.id))] control.postfix&lt;-LETTERS[seq(from=1, to=length(control.sample.id))] control.samples&lt;-paste(m$samples$group[control.sample.id], control.postfix, sep=&#39;_&#39;) case.samples&lt;-paste(m$samples$group[case.sample.id], case.postfix, sep=&#39;_&#39;) compare.name&lt;-paste0(case.groupname,&quot;.vs.&quot;,control.groupname) print(compare.name) de &lt;- ScreenBEAM.gene.level(input.file, control.samples = control.samples, case.samples = case.samples, data.type = &quot;NGS&quot;,control.groupname=control.groupname, case.groupname=case.groupname,gene.columnId=2, do.normalization=FALSE, filterLowCount=TRUE,filterBy=&#39;control&#39;,count.cutoff=4, rna.size = 6, sample.rna.time = 100, pooling = &quot;partial&quot;, method=&#39;Bayesian&#39;) names(de)[1]&lt;-&quot;geneID&quot; de.gene.list[[compare.name]]&lt;-de } if(length(de.gene.list)&gt;1){ DR.GENE.DF&lt;-de.gene.list[[1]] for(i in 2:length(de.gene.list)){ DR.GENE.DF&lt;-merge(DR.GENE.DF, de.gene.list[[i]], by=&quot;ID&quot;) } }else{ DR.GENE.DF&lt;-de.gene.list[[1]] } . Clean up your results and generate result table. . DR.GENE.DF.sel&lt;-dplyr::select(DR.GENE.DF, geneID, starts_with(&#39;log2FC.&#39;), starts_with(&#39;z.&#39;), starts_with(&#39;pval.&#39;), starts_with(&#39;FDR.&#39;), starts_with(&#39;B.&#39;), starts_with(&#39;B.sd&#39;), starts_with(&#39;n.sh_sgRNAs.passFilter.&#39;) ) write.xlsx(DR.GENE.DF.sel, paste0(analysis.par$out.dir, lib.name,&quot;.DR.GENE.xlsx&quot;)) DR.GENE.DF.sel$geneID&lt;-as.character(DR.GENE.DF.sel$geneID) . If you have NetBID2 installed, you could use built-in volcano plot function to generate volcano plot for you DR analysis. . # Take 1 comparison as example, to return the list of significant genes and draw a plot sig_gene &lt;- draw.volcanoPlot(dat=DR.GENE.DF.sel, label_col = &quot;geneID&quot;, logFC_col = names(DR.GENE.DF.sel)[2], Pv_col = names(DR.GENE.DF.sel)[5], logFC_thre = 2, Pv_thre = 1e-4, main = names(de.rna.list), show_label = T, label_cex = 1, pdf_file = paste0(analysis.par$out.dir.output.DR, names(de.gene.list),&quot;_GENE.pdf&quot;)) . Step4.Perform pairwise comparisons on shRNA level . shRNA level comparison also give another layer of information when gene level comparisons are not that informative. Statistical significance could only be computed when there are 2 or more replicates in experinment design, otherwise only folder changes (FC) will be computed successfully. . First of all, double check the group label in your comparisons are in eset$group info. . unique.group&lt;-unique(eset$group) # group label in your eset d&lt;-openxlsx::read.xlsx(&quot;20191020_CRISPR_comparisons.xlsx&quot;) # comparisons that you want to perform all(unlist(d)%in%unique.group) # make sure all group label exists in unique.group compare.pairs&lt;-t(d) # your comparisons are required to be as follows . Specify your input file: . input.file&lt;-&quot;4cl_combined_withlib_normalized_50M.tsv&quot; . Do comparisons by function ScreenBEAM.rna.level. . de.rna.list&lt;-list() # create an empty list to store following analysis results . for(i in 1:dim(compare.pairs)[2]){ case.groupname&lt;-compare.pairs[1,i] control.groupname&lt;-compare.pairs[2,i] case.sample.id&lt;-which(eset$group==compare.pairs[1,i]) control.sample.id&lt;-which(eset$group==compare.pairs[2,i]) case.postfix&lt;-LETTERS[seq(from=1, to=length(case.sample.id))] control.postfix&lt;-LETTERS[seq(from=1, to=length(control.sample.id))] control.samples&lt;-eset$group[control.sample.id] case.samples&lt;-eset$group[case.sample.id] de&lt;-ScreenBEAM.rna.level(input.file, control.samples = control.samples, case.samples = case.samples, control.groupname=control.groupname, case.groupname=case.groupname, gene.columnId=2, do.log2=TRUE, do.normalization=FALSE, total=1e6, filterLowCount=TRUE, filterBy=&#39;control&#39;,count.cutoff=8,family=gaussian,estimation.method=&#39;Bayesian&#39;) compare.name&lt;-paste0(case.groupname,&quot;.vs.&quot;,control.groupname) names(de)&lt;-paste(names(de), compare.name, sep = &quot;.&quot;) names(de)[1]&lt;-&quot;rnaID&quot; de.rna.list[[compare.name]]&lt;-de } save.image(&quot;DE.sgRNA.RData&quot;) #save your data . Merge your results by “rnaID” and combine feature information from fData(eset). . if(length(de.rna.list)&gt;1){ DR.RNA.DF&lt;-de.rna.list[[1]] for(i in 2:length(de.rna.list)){ DR.RNA.DF&lt;-merge(DR.RNA.DF, de.rna.list[[i]], by=&quot;rnaID&quot;,all.x = TRUE) } }else{ DR.RNA.DF&lt;-de.rna.list[[1]] } DR.RNA.DF&lt;-merge(DR.RNA.DF,fData(eset),by.x=&quot;rnaID&quot;,by.y=&quot;id&quot;) . Clean up your data frame using function select. Save your analysis results. . DR.RNA.DF.sel&lt;-dplyr::select(DR.RNA.DF, rnaID, gRNA.sequence:nchar, dplyr::starts_with(&#39;log2FC&#39;), dplyr::starts_with(&#39;Ave.&#39;) ) save.image(&quot;DE.sgRNA.RData&quot;) . Output your result as an excel file. . df&lt;-exprs(eset) DR.RNA.DF.sel&lt;-merge(DR.RNA.DF.sel,df,by.x=&quot;rnaID&quot;,by.y=&quot;row.names&quot;) openxlsx::write.xlsx(DR.RNA.DF.sel, &quot;4CL.2Lib.DR.sgRNA.xlsx&quot;) .",
    "url": "http://localhost:4000/docs/Tutorial3.html",
    "relUrl": "/docs/Tutorial3.html"
  }
  ,"5": {
    "title": "Running on cluster",
    "content": "Tutorial-4 Running DR analysis for large data . . Perform pairwise comparisons on Gene level by jobs in parallel | Perform pairwise comparisons on Gene level by jobs in parallel . For whole genome libraries, it may cost sometime to run these pairwise comparisons sequentially. So we recommend to generate one R script for each comparisons and running them in parallel. . Define dependencies, function path (if package is not installed) , and input files. . library(ScreenBEAM2) input.file&lt;-&quot;your_normalized_eset.tsv&quot; input.file&lt;-normalizePath(input.file) dir.tmp&lt;-&quot;DR_hpc/&quot; # directory to store individual results . load([your_stored_eset]) # define your comparisons d&lt;-openxlsx::read.xlsx(&quot;your_CRISPR_comparisons.xlsx&quot;) compare.pairs&lt;-t(d) # turn off filtering for(i in 1:dim(compare.pairs)[2]){ case.groupname&lt;-compare.pairs[1,i] control.groupname&lt;-compare.pairs[2,i] compare.name&lt;-paste0(case.groupname,&quot;.vs.&quot;,control.groupname) case.sample.id&lt;-which(eset$group==compare.pairs[1,i]) control.sample.id&lt;-which(eset$group==compare.pairs[2,i]) control.samples&lt;-eset$group[control.sample.id] case.samples&lt;-eset$group[case.sample.id] inputs&lt;-paste0(&quot;control.samples =&#39;&quot;,control.samples ,&quot;&#39;,case.samples = &#39;&quot;, case.samples, &quot;&#39;,control.groupname=&#39;&quot;, control.groupname,&quot;&#39;,case.groupname=&#39;&quot;,case.groupname,&quot;&#39;&quot;) other.args&lt;-&quot;data.type = &#39;NGS&#39;,gene.columnId=2, do.normalization=FALSE, filterLowCount=FALSE, count.cutoff=0, rna.size = 6, sample.rna.time = 100, pooling = &#39;partial&#39;, method=&#39;Bayesian&#39;&quot; fileR&lt;-paste0(&#39;DR_hpc/&#39;,compare.name,&quot;.R&quot;) sink(fileR) cat(&#39;rm(list=ls()) n&#39;,sep=&#39;&#39;) cat(&#39;setwd( &#39;&#39;,normalizePath(dir.tmp),&#39; &#39;) n&#39;,sep=&#39;&#39;) cat(&quot;source(&#39;dependencies.R&#39;) n&quot;,sep=&#39;&#39;) cat(&#39;source( &#39;&#39;,func.path,&#39; &#39;) n&#39;,sep=&#39;&#39;) cat(&#39;source( &#39;&#39;,func.util.path,&#39; &#39;) n&#39;,sep=&#39;&#39;) cat(&#39;de.gene.list&lt;-list() n&#39;,sep=&#39;&#39;) cat(&#39;print( &#39;&#39;,compare.name,&#39; &#39;) n&#39;,sep=&#39;&#39;) cat(&#39;de&lt;-ScreenBEAM.gene.level( &#39;&#39;,input.file,&#39; &#39;,&#39;,inputs, &#39;,&#39;, other.args,&#39;) n&#39;,sep=&#39;&#39;) cat(&#39;names(de)[1]&lt;-&quot;geneID&quot; n&#39;,sep=&#39;&#39;) cat(&#39;de.gene.list[[ &#39;&#39;,compare.name,&#39; &#39;]]&lt;-de&#39;, &#39; n&#39;,sep=&#39;&#39;) cat(&#39;save(de.gene.list, file= &#39;DR.gene.c&#39;,i,&#39; &#39;) n&#39;,sep = &#39;&#39;) sink() compare.name&lt;-gsub(&quot;.&quot;,&quot;_&quot;,compare.name,fixed = TRUE) file.sh&lt;-file.path(dir.tmp,paste(compare.name,&#39;sh&#39;,sep=&#39;.&#39;)) project.name&lt;-compare.name memory&lt;-paste(&#39;#BSUB -R &quot;rusage[mem=8000] &quot;&#39;) project&lt;-paste(&#39;#BSUB -P &#39;,project.name,&#39;&#39;) sh.header&lt;-paste( &#39;#!/bin/bash&#39;, project, memory, &#39;#BSUB -q standard&#39;, sep=&#39; n&#39;) sink(file.sh) cat(sh.header,&#39; n&#39;, sep = &#39;&#39;) cat(&#39;Rscript&#39;, normalizePath(fileR), sep=&#39; &#39;) sink() cmd&lt;-paste(&#39;bsub &lt; &#39;,normalizePath(file.sh),&#39; n&#39;,sep=&#39;&#39;) system(cmd) system(paste(&#39;sleep &#39;,1,&#39; n&#39;)) cat(cmd) } .",
    "url": "http://localhost:4000/docs/hpc_tutorial.html",
    "relUrl": "/docs/hpc_tutorial.html"
  }
  ,"6": {
    "title": "Home",
    "content": "ScreenBEAM2 . Gene-level meta-analysis of high-throughput functional genomics screens . Get started now View it on GitHub . . Overview . ScreenBEAM2 is the upgraded version of ScreenBEAM1. It can perform functional genomics screening from FASTQ file. It is a trim-free, allowing number of mismatch, BLAT-dependent pipeline. Downstream analysis uses Bayesian hierarchical modeling, removed bias caused by the unbalanced number of sh/sgRNA targeting the same gene. . Citing ScreenBEAM2 . If ScreenBEAM2 is useful to your work, please cite the following paper: Yu J, Silva, J, Califano A. ScreenBEAM: a Novel Meta-Analysis Algorithm for Functional Genomics Screens via Bayesian Hierarchical Modeling. _Bioinformatics, 2015 Sep 28. pii: btv556. . Contact . The ScreenBEAM2 software is developed by Yu Lab at St. Jude Children’s Research Hospital. . We’re very interested to hear feedback about using ScreenBEAM2 in your analysis. If you find any issues/bugs, or have any suggestions, please don’t hesitate to create issues in GitHub, or contact us directly. .",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  }
  
}